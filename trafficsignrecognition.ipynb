{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-04-25T04:16:44.120483Z","iopub.status.busy":"2022-04-25T04:16:44.120005Z","iopub.status.idle":"2022-04-25T04:16:51.034358Z","shell.execute_reply":"2022-04-25T04:16:51.033448Z","shell.execute_reply.started":"2022-04-25T04:16:44.120400Z"},"trusted":true},"outputs":[],"source":["# Importing necessary libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import os\n","import cv2\n","import csv\n","import random\n","from matplotlib.image import imread\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow import keras\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import accuracy_score\n","from keras.models import Sequential, load_model\n","from keras.applications.vgg19 import VGG19\n","from keras.layers import BatchNormalization, Dense, Flatten, Dropout\n","from time import time\n","\n","np.random.seed(42)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:16:51.039245Z","iopub.status.busy":"2022-04-25T04:16:51.038971Z","iopub.status.idle":"2022-04-25T04:16:51.044120Z","shell.execute_reply":"2022-04-25T04:16:51.043147Z","shell.execute_reply.started":"2022-04-25T04:16:51.039212Z"},"trusted":true},"outputs":[],"source":["# Extracting data\n","data_dir = '../input/gtsrb-german-traffic-sign'\n","train_path = data_dir + '/Train'\n","test_path = data_dir + '/'\n","\n","# Resizing the images to 32x32x3\n","IMG_HEIGHT = 32\n","IMG_WIDTH = 32\n","channels = 3"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:16:51.045590Z","iopub.status.busy":"2022-04-25T04:16:51.045257Z","iopub.status.idle":"2022-04-25T04:16:51.097170Z","shell.execute_reply":"2022-04-25T04:16:51.096395Z","shell.execute_reply.started":"2022-04-25T04:16:51.045563Z"},"trusted":true},"outputs":[],"source":["# Finding total classes\n","NUM_CATEGORIES = len(os.listdir(train_path))\n","NUM_CATEGORIES"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:16:51.099453Z","iopub.status.busy":"2022-04-25T04:16:51.099095Z","iopub.status.idle":"2022-04-25T04:16:51.106649Z","shell.execute_reply":"2022-04-25T04:16:51.105584Z","shell.execute_reply.started":"2022-04-25T04:16:51.099420Z"},"trusted":true},"outputs":[],"source":["# Defining Label Overview\n","classes = { 0:'Speed limit (20km/h)',\n","            1:'Speed limit (30km/h)',\n","            2:'Speed limit (50km/h)',\n","            3:'Speed limit (60km/h)',\n","            4:'Speed limit (70km/h)',\n","            5:'Speed limit (80km/h)',\n","            6:'End of speed limit (80km/h)',\n","            7:'Speed limit (100km/h)',\n","            8:'Speed limit (120km/h)',\n","            9:'No passing',\n","            10:'No passing veh over 3.5 tons',\n","            11:'Right-of-way at intersection',\n","            12:'Priority road',\n","            13:'Yield',\n","            14:'Stop',\n","            15:'No vehicles',\n","            16:'Veh > 3.5 tons prohibited',\n","            17:'No entry',\n","            18:'General caution',\n","            19:'Dangerous curve left',\n","            20:'Dangerous curve right',\n","            21:'Double curve',\n","            22:'Bumpy road',\n","            23:'Slippery road',\n","            24:'Road narrows on the right',\n","            25:'Road work',\n","            26:'Traffic signals',\n","            27:'Pedestrians',\n","            28:'Children crossing',\n","            29:'Bicycles crossing',\n","            30:'Beware of ice/snow',\n","            31:'Wild animals crossing',\n","            32:'End speed + passing limits',\n","            33:'Turn right ahead',\n","            34:'Turn left ahead',\n","            35:'Ahead only',\n","            36:'Go straight or right',\n","            37:'Go straight or left',\n","            38:'Keep right',\n","            39:'Keep left',\n","            40:'Roundabout mandatory',\n","            41:'End of no passing',\n","            42:'End no passing veh > 3.5 tons' }"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:16:51.108975Z","iopub.status.busy":"2022-04-25T04:16:51.107796Z","iopub.status.idle":"2022-04-25T04:17:01.056274Z","shell.execute_reply":"2022-04-25T04:17:01.055413Z","shell.execute_reply.started":"2022-04-25T04:16:51.108796Z"},"trusted":true},"outputs":[],"source":["# Visualizing the dataset\n","folders = os.listdir(train_path)\n","\n","train_number = []\n","class_names = []\n","\n","for folder in folders:\n","    \n","    train_files = os.listdir(train_path + '/' + folder)\n","    train_number.append(len(train_files))\n","    class_names.append(classes[int(folder)])\n","    \n","# Sorting the dataset on the basis of number of images in each class\n","zipped_lists = zip(train_number, class_names)\n","sorted_pairs = sorted(zipped_lists)\n","tuples = zip(*sorted_pairs)\n","train_number, class_names = [ list(tuple) for tuple in  tuples]\n","\n","# Plotting the number of images in each class\n","plt.figure(figsize=(21,10))  \n","plt.barh(class_names, train_number)\n","plt.yticks(class_names)\n","plt.xlabel('Count')\n","plt.ylabel('Classes')\n","for index, value in enumerate(train_number):\n","    plt.text(value, index,\n","             str(value))\n","plt.show()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:17:01.057759Z","iopub.status.busy":"2022-04-25T04:17:01.057440Z","iopub.status.idle":"2022-04-25T04:17:04.193847Z","shell.execute_reply":"2022-04-25T04:17:04.192818Z","shell.execute_reply.started":"2022-04-25T04:17:01.057717Z"},"trusted":true},"outputs":[],"source":["# Data Visualizing random images from the test data\n","test = pd.read_csv(data_dir + '/Test.csv')\n","imgs = test[\"Path\"].values\n","\n","plt.figure(figsize=(25,25))\n","\n","for i in range(1,21):\n","    plt.subplot(5,5,i)\n","    random_img_path = data_dir + '/' + random.choice(imgs)\n","    rand_img = imread(random_img_path)\n","    plt.imshow(rand_img)\n","    plt.grid(b=None)\n","    plt.xlabel(rand_img.shape[1], fontsize = 20)#width of image\n","    plt.ylabel(rand_img.shape[0], fontsize = 20)#height of image"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:17:04.195740Z","iopub.status.busy":"2022-04-25T04:17:04.195445Z","iopub.status.idle":"2022-04-25T04:17:04.212017Z","shell.execute_reply":"2022-04-25T04:17:04.211068Z","shell.execute_reply.started":"2022-04-25T04:17:04.195691Z"},"trusted":true},"outputs":[],"source":["# Basic preprocessing and mixing of dataset\n","def preprocess(image, out_side):\n","    height, width = image.shape[:2]\n","    scale = out_side / max(height, width)\n","    dx = (out_side - scale * width) / 2\n","    dy = (out_side - scale * height) / 2\n","    trans = np.array([[scale, 0, dx], [0, scale, dy]], dtype=np.float32)\n","    image = cv2.warpAffine(image, trans, (out_side, out_side), flags=cv2.INTER_AREA)\n","    image = cv2.resize(image, (out_side, out_side))\n","    return image\n","\n","def mixing(images, labels):\n","    images = np.array(images)\n","    labels = np.array(labels)\n","    s = np.arange(images.shape[0])\n","    np.random.seed(43)\n","    np.random.shuffle(s)\n","    images=images[s]\n","    labels=labels[s]\n","    return images, labels\n","\n","def load_train(path, out_side):\n","    images = []\n","    labels = []\n","    for folder in os.listdir(os.path.join(path, 'Train')):\n","        cur_path = os.path.join(path, 'Train', folder)\n","        for file_name in os.listdir(cur_path):\n","            image = cv2.imread(os.path.join(cur_path, file_name))\n","            images.append(preprocess(image, out_side))\n","            labels.append(int(folder))\n","\n","    return mixing(images, labels)\n","\n","def load_test(path, out_side):\n","    images = []\n","    labels = []\n","    with open(os.path.join(path, 'Test.csv'), 'r') as f:\n","        reader = csv.reader(f)\n","        for rows in reader:\n","            name = rows[7]\n","            if (name == 'Path'):\n","                continue\n","            image = cv2.imread(os.path.join(path, rows[7]))\n","            images.append(preprocess(image, out_side))\n","            labels.append(int(rows[6]))\n","\n","    return mixing(images, labels)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:17:04.213640Z","iopub.status.busy":"2022-04-25T04:17:04.213013Z","iopub.status.idle":"2022-04-25T04:23:45.717276Z","shell.execute_reply":"2022-04-25T04:23:45.716416Z","shell.execute_reply.started":"2022-04-25T04:17:04.213607Z"},"trusted":true},"outputs":[],"source":["start = time()\n","\n","train_images, train_labels = load_train(data_dir + \"/\", 32)\n","test_images, test_labels = load_test(data_dir + \"/\", 32)\n","shape = train_images[0].shape\n","print(shape)\n","\n","# normalizing the images data\n","train_images = train_images.astype('float32') / 255.\n","test_images = test_images.astype('float32') / 255.\n","\n","# One-hot encoding the labels \n","train_labels = to_categorical(train_labels, NUM_CATEGORIES)\n","test_labels = to_categorical(test_labels, NUM_CATEGORIES)\n","\n","print('Loading: ', time() - start)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:23:45.718845Z","iopub.status.busy":"2022-04-25T04:23:45.718612Z","iopub.status.idle":"2022-04-25T04:23:45.944120Z","shell.execute_reply":"2022-04-25T04:23:45.943262Z","shell.execute_reply.started":"2022-04-25T04:23:45.718818Z"},"trusted":true},"outputs":[],"source":["# Splitting th dataset\n","X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, random_state=42, shuffle=True)\n","\n","print(\"X_train.shape - \", X_train.shape)\n","print(\"X_valid.shape - \", X_val.shape)\n","print(\"y_train.shape - \", y_train.shape)\n","print(\"y_valid.shape - \", y_val.shape)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:23:45.945376Z","iopub.status.busy":"2022-04-25T04:23:45.945168Z","iopub.status.idle":"2022-04-25T04:23:45.952548Z","shell.execute_reply":"2022-04-25T04:23:45.951216Z","shell.execute_reply.started":"2022-04-25T04:23:45.945350Z"},"trusted":true},"outputs":[],"source":["# Image augmentation for better performance\n","train_image_aug = ImageDataGenerator(\n","                            rotation_range=10,\n","                            zoom_range=0.15,\n","                            width_shift_range=0.1,\n","                            height_shift_range=0.1,\n","                            shear_range=0.15,\n","                            horizontal_flip=False,\n","                            vertical_flip=False,\n","                            fill_mode=\"nearest\")\n","\n","# Applying data augmentation to features\n","BATCH_SIZE= 128\n","train_gen = train_image_aug.flow(X_train, y_train, batch_size= BATCH_SIZE)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:23:45.955184Z","iopub.status.busy":"2022-04-25T04:23:45.954575Z","iopub.status.idle":"2022-04-25T04:23:47.818191Z","shell.execute_reply":"2022-04-25T04:23:47.817170Z","shell.execute_reply.started":"2022-04-25T04:23:45.955140Z"},"trusted":true},"outputs":[],"source":["# Creating model with VGG19 base (transfer learning)\n","vgg_conv_base = VGG19(weights='imagenet', include_top=False, input_shape=(32,32,3)) \n","\n","vgg_model = Sequential()\n","vgg_model.add(vgg_conv_base)\n","vgg_model.add(BatchNormalization())\n","vgg_model.add(Flatten())\n","vgg_model.add(Dense(1024, activation='relu'))\n","vgg_model.add(Dropout(rate=0.5))\n","vgg_model.add(Dense(NUM_CATEGORIES, activation='softmax'))"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:23:47.819872Z","iopub.status.busy":"2022-04-25T04:23:47.819521Z","iopub.status.idle":"2022-04-25T04:23:47.838419Z","shell.execute_reply":"2022-04-25T04:23:47.837847Z","shell.execute_reply.started":"2022-04-25T04:23:47.819833Z"},"trusted":true},"outputs":[],"source":["LR = 0.0001 # learning rate\n","EPOCHS = 10\n","\n","opt = Adam(lr=LR)\n","\n","# Compiling the model\n","vgg_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:23:47.842432Z","iopub.status.busy":"2022-04-25T04:23:47.841852Z","iopub.status.idle":"2022-04-25T04:23:47.853152Z","shell.execute_reply":"2022-04-25T04:23:47.852303Z","shell.execute_reply.started":"2022-04-25T04:23:47.842389Z"},"trusted":true},"outputs":[],"source":["# Model summary\n","vgg_model.summary()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:23:47.855021Z","iopub.status.busy":"2022-04-25T04:23:47.854341Z","iopub.status.idle":"2022-04-25T06:35:19.363619Z","shell.execute_reply":"2022-04-25T06:35:19.362050Z","shell.execute_reply.started":"2022-04-25T04:23:47.854985Z"},"trusted":true},"outputs":[],"source":["# Model training\n","history = vgg_model.fit(train_gen, epochs=EPOCHS, validation_data=(X_val, y_val), shuffle= True)\n","\n","# Saving model\n","vgg_model.save(\"trafficsignrecognition_model.h5\")"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T06:35:19.368827Z","iopub.status.busy":"2022-04-25T06:35:19.368487Z","iopub.status.idle":"2022-04-25T06:35:19.733061Z","shell.execute_reply":"2022-04-25T06:35:19.732112Z","shell.execute_reply.started":"2022-04-25T06:35:19.368789Z"},"trusted":true},"outputs":[],"source":["# Plotting the history \n","plt.figure(figsize=(12, 12))\n","plt.subplot(3, 2, 1)\n","plt.plot(history.history['accuracy'], label = 'Train Accuracy')\n","plt.plot(history.history['val_accuracy'], label = 'Val Accuracy')\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.legend()\n","plt.subplot(3, 2, 2)\n","plt.plot(history.history['loss'], label = 'Train Loss')\n","plt.plot(history.history['val_loss'], label = 'Val Loss')\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T06:35:19.735350Z","iopub.status.busy":"2022-04-25T06:35:19.734799Z","iopub.status.idle":"2022-04-25T06:36:48.764584Z","shell.execute_reply":"2022-04-25T06:36:48.763732Z","shell.execute_reply.started":"2022-04-25T06:35:19.735312Z"},"trusted":true},"outputs":[],"source":["# Model evaluation\n","test_loss, test_acc = vgg_model.evaluate(test_images, test_labels)\n","\n","print('Test accuracy:', test_acc)\n","print('Test loss:', test_loss)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T06:36:48.766460Z","iopub.status.busy":"2022-04-25T06:36:48.766234Z","iopub.status.idle":"2022-04-25T06:38:50.917213Z","shell.execute_reply":"2022-04-25T06:38:50.916250Z","shell.execute_reply.started":"2022-04-25T06:36:48.766432Z"},"trusted":true},"outputs":[],"source":["test = pd.read_csv(data_dir + '/Test.csv')\n","\n","labels = test[\"ClassId\"].values\n","imgs = test[\"Path\"].values\n","\n","data =[]\n","\n","for img in imgs:\n","    try:\n","        image = cv2.imread(data_dir + '/' +img)\n","        image_fromarray = Image.fromarray(image, 'RGB')\n","        resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n","        data.append(np.array(resize_image))\n","    except:\n","        print(\"Error in \" + img)\n","X_test = np.array(data)\n","X_test = X_test/255\n","\n","\n","predict_x=vgg_model.predict(X_test) \n","pred=np.argmax(predict_x,axis=1)\n","\n","#Accuracy with the test data\n","print('Test Data accuracy: ',accuracy_score(labels, pred)*100)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T07:21:51.898897Z","iopub.status.busy":"2022-04-25T07:21:51.898320Z","iopub.status.idle":"2022-04-25T07:21:53.390443Z","shell.execute_reply":"2022-04-25T07:21:53.389486Z","shell.execute_reply.started":"2022-04-25T07:21:51.898860Z"},"trusted":true},"outputs":[],"source":["# Model prediction\n","plt.figure(figsize = (25, 25))\n","\n","start_index = 0\n","for i in range(25):\n","    plt.subplot(5, 5, i + 1)\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","    prediction = pred[start_index + i]\n","    actual = labels[start_index + i]\n","    col = 'g'\n","    if prediction != actual:\n","        col = 'r'\n","    plt.title('Actual={}'.format(classes[int(actual)]), color = col)\n","    plt.xlabel('Predicted={}'.format(classes[int(prediction)]), color = col)\n","    plt.imshow(X_test[start_index + i])\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
